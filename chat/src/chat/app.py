import logging
import streamlit as st

from core.bootstrap.container import initialize
from core.bootstrap.vo import ArxivSearcherConfig, AzureConfig
from core.bootstrap.vo import ModelType
from core.framework.driving_adaptor import ArxivAgent

logging.basicConfig(level=logging.DEBUG)

st.title("ðŸ”Ž Arxiv Assistant")
"""
Arxiv Assistant helps you to search proper arxiv papers.

[Source Code](https://github.com/sad-zero/arxiv-assistant.git)
"""

with st.sidebar:
    with st.container(border=True):
        "Register your keys"
        openai_api_key = st.text_input(
            "OpenAI API Key", key="chatbot_api_key", type="password"
        )
        "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"

        with st.container(border=True):
            "Azure AI Studio Config"
            endpoint: str = st.text_input("Azure AI Studio Deployment's endpoint")
            deployment: str = st.text_input("Azure AI Studio Deployment's name")
            api_version: str = st.text_input("Azure AI Studio Deployment's api version")
            api_key: str = st.text_input(
                "Azure AI Studio Deployment's secret", type="password"
            )
            azure_config: AzureConfig = AzureConfig(
                endpoint=endpoint,
                deployment=deployment,
                api_version=api_version,
                api_key=api_key,
            )
    with st.container(border=True):
        "Arxiv Searcher Options"
        model_type_str: str = st.selectbox(
            "Selectable LLM",
            map(lambda x: x.value, iter(ModelType)),
        )
        model_type: ModelType = ModelType(model_type_str)
        if model_type == ModelType.OLLAMA_LLAMA3_1:
            "Please install and run ollama"
            "[Ollama Manual](https://ollama.com)"

        max_documents: int = int(
            st.number_input("Max documents", min_value=1, max_value=10, step=1)
        )

        arxiv_searcher_config: ArxivSearcherConfig = ArxivSearcherConfig(
            max_documents=max_documents,
            model_type=model_type,
        )

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "assistant",
            "content": "Hi, I'am arxiv assistant. I can search arxiv and answer your question. What can I do for you?",
        }
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).markdown(msg["content"])

if query := st.chat_input(placeholder="What is prompt engineering?"):
    st.session_state.messages.append({"role": "user", "content": query})
    st.chat_message("user").markdown(query)
    arxiv_agent: ArxivAgent = initialize(
        configs={
            "arxiv_searcher": arxiv_searcher_config,
            "azure": azure_config,
        },
        openai_key=openai_api_key,
    )

    with st.chat_message("assistant"):
        response = arxiv_agent.search(query)
        answer = f"*Generated by {model_type.value}*\n\n"
        answer += f"{response.answer}\n\n"
        answer += "# Related Papers\n"
        for abstract in response.data:
            answer += f"- [{abstract.title}]({abstract.link})\n"
        st.session_state.messages.append(
            {"role": "assistant", "content": answer.strip()}
        )
        st.markdown(answer)
